<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <link rel="shortcut icon" href="/static/img/favicon.ico" />
        <title>lovetoken</title>
        <meta name="author" content="Lovetoken" />
        <meta name="description" content="R에서 caret package 를 이용한 데이터 학습 간편화 전략" />
        <meta name="keywords" content="R에서 caret package 를 이용한 데이터 학습 간편화 전략, , R" />
        <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml">

        <meta content="" property="fb:app_id">
        <meta content="" property="og:site_name">
        
          <meta content="R에서 caret package 를 이용한 데이터 학습 간편화 전략" property="og:title">
        
        
          <meta content="article" property="og:type">
        
        
          <meta content="" property="og:description">
        
        
          <meta content="https://lovetoken.github.io/r/2017/04/23/caret_package.html" property="og:url">
        
        
          <meta content="2017-04-23T00:00:00+09:00" property="article:published_time">
          <meta content="https://lovetoken.github.io/about/" property="article:author">
        
        
          <meta content="https://lovetoken.github.io/static/img/logo-high-resolution.png" property="og:image">
        
        
          
          <meta content="R" property="article:section">
          
        
        
          
        

        <meta name="twitter:card" content="summary">
        <meta name="twitter:site" content="@">
        <meta name="twitter:creator" content="@">
        
          <meta name="twitter:title" content="R에서 caret package 를 이용한 데이터 학습 간편화 전략">
        
        
          <meta name="twitter:url" content="https://lovetoken.github.io/r/2017/04/23/caret_package.html">
        
        
          <meta name="twitter:description" content="">
        
        

        <!-- Font awesome icons -->
        <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

        <!-- syntax highlighting CSS -->
        <link rel="stylesheet" href="/static/css/syntax.css">

        <!-- Bootstrap core CSS -->
        <link href="/static/css/bootstrap.min.css" rel="stylesheet">

        <!-- Fonts -->
        <link href="//fonts.googleapis.com/css?family=Roboto+Condensed:400,300italic,300,400italic,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">

        <!-- Custom CSS -->        
        <link rel="stylesheet" href="/static/css/super-search.css">
        <link rel="stylesheet" href="/static/css/thickbox.css">
        <link rel="stylesheet" href="/static/css/projects.css">
        <link rel="stylesheet" href="/static/css/main.css">

        <!-- Google Analytics -->
        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
          
          ga('create', 'UA-89656101-1', 'auto');
          ga('send', 'pageview');
        </script>

    </head>

    <body>
        <div class="container">
            <div class="col-sm-3">
              <div class="fixed-condition">
                <a href="/"><img id="about" src="/static/img/avatar.jpg" height="75px" width="75px" /></a>
                <h1 class="author-name">Lovetoken</h1>
                
                <div id="about">
                    저는 개발 취향을 가진 데이터 분석가 Jr. 입니다.
                </div>
                

                <div class="social">
                    <ul>
                        
                            <li><a href="https://twitter.com/LT_Lovetoken" target="_blank"><i class="fa fa-twitter"></i></a></li>
                        
                            <li><a href="https://www.linkedin.com/in/lovetoken/" target="_blank"><i class="fa fa-linkedin"></i></a></li>
                        
                    </ul>
                </div>

                <div class="search" id="js-search">
                  <input type="text" placeholder="(sitemap)~$ type to search" class="search__input form-control" id="js-search__input">
                  <ul class="search__results" id="js-search__results"></ul>
                </div>
                <hr />

                <strong>Navigation</strong><br />
                    &nbsp;&raquo; <a href="/">Home</a> <br />
                
                    &nbsp;&raquo; <a class="about" href="/about/">About Me</a><br />
                
                    &nbsp;&raquo; <a class="about" href="https://github.com/lovetoken">Github</a><br />
                
              </div><!-- end /.fixed-condition -->
            </div>

            <div class="col-sm-8 col-offset-1">
                <h1>R에서 caret package 를 이용한 데이터 학습 간편화 전략</h1>
<span class="time">23 Apr 2017</span>

<span class="categories">
    &raquo; <a href="/category/R">R</a>
</span>


<div class="content">
    <div class="post"><p><br><br></p>
<p>기계학습(Machine Learning) 에서 기법이 무엇이 되든, 어떤 알고리즘을 사용할 것이든 공통으로 필요한 과정은 &quot;Learning&quot; 즉 &quot;학습&quot;이다.<br />
학습의 대상은 전통적으로 훈련데이터(Training dataset)이고, 훈련데이터를 학습시키는 아주 다양한 방법들이 존재한다.<br />
방법별로 원리와 특징 및 색깔이 다르며, 무엇보다 <strong>워낙 다양한 방법들이 존재하기 때문</strong>에 아무리 많이 공부를 한 사람이라 한들 모든 알고리즘을 아는것이 한계가 있다고 생각한다.<br />
때문에 무엇을 채택해서 어느 정도의 파라미터값을 부여해야 알맞은 모델을 만들 수 있을지 현실적인 문제에 부딪히게 된다.</p>
<p>R에서 배포되고 있는 머신러닝 관련 패키지의 개수는 <a href="https://cran.r-project.org/web/views/MachineLearning.html">CRAN Task View: Machine Learning &amp; Statistical Learning</a>만을 보아도 수십개가 된다.<br />
이 패키지들을 모두 하나하나 실행해서 상황에 맞는 모델링을 하기 위해 비교실험을 해보는 것도 가능할 것이다.<br />
하지만 패키지별로 사용방식이 많이 다를 수 있어 이를 인지하는데도 많은 시간이 걸리고, 비교해보고 싶은 알고리즘의 패키지를 찾아 설치하고 로드하는 것 마저 부담으로 다가올 수 있겠다.</p>
<p>이러한 상황에서 caret 패키지는 예측모델을 만들기 위한 데이터 학습 시 간편한 함수를 제공해 준다.<br />
특히 금일<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>기준 242개의 머신러닝 알고리즘을 표준화된 인터페이스를 통해 테스트 해 볼 수 있도록 준비가 되어 있고,<br />
이에 대해서 다양한 파라미터 시나리오를 구성해 손쉽게 튜닝해주고 변수의 중요도를 측정해준다.<br />
사용자는 편리한 훈련데이터의 학습을 통해 적절한 알고리즘 선택 의사결정에 도움을 받을 수 있다.</p>
<p>이러한 기대효과를 가진 caret package 에 대해 소개하는 시간을 가져보도록 하겠다.</p>
<br>
<center>
<img src="/assets/caret.png" />
</center>
<p><br></p>
<p>caret 패키지의 명칭은 &quot;<strong>C</strong>lassification <strong>A</strong>nd <strong>RE</strong>gression <strong>T</strong>raining&quot; 의 앞글자를 따와 명명되었다.<br />
주 관심 대상이 되는 종속변수(예측변수)가 명목형 변수라면 &quot;Classification&quot;, 연속형 변수라면 &quot;Regression&quot; 으로 갈피를 잡아 &quot;Training&quot; 을 하게 될 텐데, 이 과정을 caret 패키지를 이용해 코딩해 본 가장 간단한 예제로 시작해 보겠다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse) <span class="co"># for tidy tools (pipe operation, tibble, etc..)</span>
<span class="kw">library</span>(caret)

<span class="kw">set.seed</span>(<span class="dv">1234</span>) <span class="co"># for reproducibility</span>

<span class="kw">data</span>(Sonar, <span class="dt">package =</span> <span class="st">&quot;mlbench&quot;</span>)
Sonar &lt;-<span class="st"> </span>Sonar %&gt;%<span class="st"> </span>tbl_df
Sonar</code></pre></div>
<pre><code>## # A tibble: 208 x 61
##        V1     V2     V3     V4     V5     V6     V7     V8     V9    V10
## *   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1  0.0200 0.0371 0.0428 0.0207 0.0954 0.0986 0.1539 0.1601 0.3109 0.2111
## 2  0.0453 0.0523 0.0843 0.0689 0.1183 0.2583 0.2156 0.3481 0.3337 0.2872
## 3  0.0262 0.0582 0.1099 0.1083 0.0974 0.2280 0.2431 0.3771 0.5598 0.6194
## 4  0.0100 0.0171 0.0623 0.0205 0.0205 0.0368 0.1098 0.1276 0.0598 0.1264
## 5  0.0762 0.0666 0.0481 0.0394 0.0590 0.0649 0.1209 0.2467 0.3564 0.4459
## 6  0.0286 0.0453 0.0277 0.0174 0.0384 0.0990 0.1201 0.1833 0.2105 0.3039
## 7  0.0317 0.0956 0.1321 0.1408 0.1674 0.1710 0.0731 0.1401 0.2083 0.3513
## 8  0.0519 0.0548 0.0842 0.0319 0.1158 0.0922 0.1027 0.0613 0.1465 0.2838
## 9  0.0223 0.0375 0.0484 0.0475 0.0647 0.0591 0.0753 0.0098 0.0684 0.1487
## 10 0.0164 0.0173 0.0347 0.0070 0.0187 0.0671 0.1056 0.0697 0.0962 0.0251
## # ... with 198 more rows, and 51 more variables: V11 &lt;dbl&gt;, V12 &lt;dbl&gt;,
## #   V13 &lt;dbl&gt;, V14 &lt;dbl&gt;, V15 &lt;dbl&gt;, V16 &lt;dbl&gt;, V17 &lt;dbl&gt;, V18 &lt;dbl&gt;,
## #   V19 &lt;dbl&gt;, V20 &lt;dbl&gt;, V21 &lt;dbl&gt;, V22 &lt;dbl&gt;, V23 &lt;dbl&gt;, V24 &lt;dbl&gt;,
## #   V25 &lt;dbl&gt;, V26 &lt;dbl&gt;, V27 &lt;dbl&gt;, V28 &lt;dbl&gt;, V29 &lt;dbl&gt;, V30 &lt;dbl&gt;,
## #   V31 &lt;dbl&gt;, V32 &lt;dbl&gt;, V33 &lt;dbl&gt;, V34 &lt;dbl&gt;, V35 &lt;dbl&gt;, V36 &lt;dbl&gt;,
## #   V37 &lt;dbl&gt;, V38 &lt;dbl&gt;, V39 &lt;dbl&gt;, V40 &lt;dbl&gt;, V41 &lt;dbl&gt;, V42 &lt;dbl&gt;,
## #   V43 &lt;dbl&gt;, V44 &lt;dbl&gt;, V45 &lt;dbl&gt;, V46 &lt;dbl&gt;, V47 &lt;dbl&gt;, V48 &lt;dbl&gt;,
## #   V49 &lt;dbl&gt;, V50 &lt;dbl&gt;, V51 &lt;dbl&gt;, V52 &lt;dbl&gt;, V53 &lt;dbl&gt;, V54 &lt;dbl&gt;,
## #   V55 &lt;dbl&gt;, V56 &lt;dbl&gt;, V57 &lt;dbl&gt;, V58 &lt;dbl&gt;, V59 &lt;dbl&gt;, V60 &lt;dbl&gt;,
## #   Class &lt;fctr&gt;</code></pre>
<p>예제에 사용할 데이터셋은 <code>mlbench::Sonar</code> 을 이용해보겠으며 예측대상변수는 <code>Class</code> 라는 명칭의 명목형으로 M, R 2개의 이분값이 담겨있다.<br />
이를 예측하는 다양한 모델을 만들어 볼 것이다.</p>
<p><br><br></p>
<h2 id="createdatapartition-함수"><code>createDataPartition()</code> 함수</h2>
<p>첫번째로 훈련데이터셋(Training dataset)과 테스트데이터셋(Test dataset)을 나누어 추후에 모델평가에 이용할 준비를 해보겠다. 비율은 70%를 훈련데이터셋에 배정하겠다.<br />
<code>sample()</code> 함수를 이용해 훈련데이터셋과 테스트데이터셋의 파티셔닝을 해 볼 수 있지만</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">indexTrain &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(Sonar), <span class="kw">round</span>(<span class="kw">nrow</span>(Sonar) *<span class="st"> </span>.<span class="dv">7</span>))
training &lt;-<span class="st"> </span>Sonar[ indexTrain, ]
testing  &lt;-<span class="st"> </span>Sonar[-indexTrain, ]</code></pre></div>
<p>caret 패키지에 있는 <code>createDataPartition()</code> 함수를 이용해 볼 수도 있다.<br />
이 함수에는 <code>p</code> 인자가 있어 특정비율로 파티셔닝할 때 편하다.<br />
또한 위의 예제코드 <code>sample()</code> 함수를 이용할 때는 <a href="https://ko.wikipedia.org/wiki/%EB%8B%A8%EC%88%9C_%EB%AC%B4%EC%9E%91%EC%9C%84_%EC%B6%94%EC%B6%9C%EB%B2%95">완전무작위추출(SRS; Simple Random Sampling)</a> 이 되기 때문에 종속변수의 요인별 비율을 고려하지 않고 무작위 샘플링이 되지만, <code>createDataPartition()</code> 함수를 이용할 경우 종속변수의 요인별 비율만큼 층화랜덤추출을 기본적으로 지원하기 때문에 안전하고 요긴하다.<br />
단 반환되는 타입이 기본적으로 list 이므로 <code>list</code> 인자값을 <code>FALSE</code>로 해 보았다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">indexTrain &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(Sonar$Class, <span class="dt">p =</span> .<span class="dv">7</span>, <span class="dt">list =</span> F)
training &lt;-<span class="st"> </span>Sonar[ indexTrain, ]
testing  &lt;-<span class="st"> </span>Sonar[-indexTrain, ]</code></pre></div>
<p>7:3 비율만큼 잘 파티셔닝이 되어있는지 확인해 보면</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">training</code></pre></div>
<pre><code>## # A tibble: 148 x 61
##        V1     V2     V3     V4     V5     V6     V7     V8     V9    V10
##     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1  0.0262 0.0582 0.1099 0.1083 0.0974 0.2280 0.2431 0.3771 0.5598 0.6194
## 2  0.0100 0.0171 0.0623 0.0205 0.0205 0.0368 0.1098 0.1276 0.0598 0.1264
## 3  0.0286 0.0453 0.0277 0.0174 0.0384 0.0990 0.1201 0.1833 0.2105 0.3039
## 4  0.0519 0.0548 0.0842 0.0319 0.1158 0.0922 0.1027 0.0613 0.1465 0.2838
## 5  0.0223 0.0375 0.0484 0.0475 0.0647 0.0591 0.0753 0.0098 0.0684 0.1487
## 6  0.0164 0.0173 0.0347 0.0070 0.0187 0.0671 0.1056 0.0697 0.0962 0.0251
## 7  0.0039 0.0063 0.0152 0.0336 0.0310 0.0284 0.0396 0.0272 0.0323 0.0452
## 8  0.0123 0.0309 0.0169 0.0313 0.0358 0.0102 0.0182 0.0579 0.1122 0.0835
## 9  0.0090 0.0062 0.0253 0.0489 0.1197 0.1589 0.1392 0.0987 0.0955 0.1895
## 10 0.0298 0.0615 0.0650 0.0921 0.1615 0.2294 0.2176 0.2033 0.1459 0.0852
## # ... with 138 more rows, and 51 more variables: V11 &lt;dbl&gt;, V12 &lt;dbl&gt;,
## #   V13 &lt;dbl&gt;, V14 &lt;dbl&gt;, V15 &lt;dbl&gt;, V16 &lt;dbl&gt;, V17 &lt;dbl&gt;, V18 &lt;dbl&gt;,
## #   V19 &lt;dbl&gt;, V20 &lt;dbl&gt;, V21 &lt;dbl&gt;, V22 &lt;dbl&gt;, V23 &lt;dbl&gt;, V24 &lt;dbl&gt;,
## #   V25 &lt;dbl&gt;, V26 &lt;dbl&gt;, V27 &lt;dbl&gt;, V28 &lt;dbl&gt;, V29 &lt;dbl&gt;, V30 &lt;dbl&gt;,
## #   V31 &lt;dbl&gt;, V32 &lt;dbl&gt;, V33 &lt;dbl&gt;, V34 &lt;dbl&gt;, V35 &lt;dbl&gt;, V36 &lt;dbl&gt;,
## #   V37 &lt;dbl&gt;, V38 &lt;dbl&gt;, V39 &lt;dbl&gt;, V40 &lt;dbl&gt;, V41 &lt;dbl&gt;, V42 &lt;dbl&gt;,
## #   V43 &lt;dbl&gt;, V44 &lt;dbl&gt;, V45 &lt;dbl&gt;, V46 &lt;dbl&gt;, V47 &lt;dbl&gt;, V48 &lt;dbl&gt;,
## #   V49 &lt;dbl&gt;, V50 &lt;dbl&gt;, V51 &lt;dbl&gt;, V52 &lt;dbl&gt;, V53 &lt;dbl&gt;, V54 &lt;dbl&gt;,
## #   V55 &lt;dbl&gt;, V56 &lt;dbl&gt;, V57 &lt;dbl&gt;, V58 &lt;dbl&gt;, V59 &lt;dbl&gt;, V60 &lt;dbl&gt;,
## #   Class &lt;fctr&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testing</code></pre></div>
<pre><code>## # A tibble: 60 x 61
##        V1     V2     V3     V4     V5     V6     V7     V8     V9    V10
##     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1  0.0200 0.0371 0.0428 0.0207 0.0954 0.0986 0.1539 0.1601 0.3109 0.2111
## 2  0.0453 0.0523 0.0843 0.0689 0.1183 0.2583 0.2156 0.3481 0.3337 0.2872
## 3  0.0762 0.0666 0.0481 0.0394 0.0590 0.0649 0.1209 0.2467 0.3564 0.4459
## 4  0.0317 0.0956 0.1321 0.1408 0.1674 0.1710 0.0731 0.1401 0.2083 0.3513
## 5  0.0079 0.0086 0.0055 0.0250 0.0344 0.0546 0.0528 0.0958 0.1009 0.1240
## 6  0.0124 0.0433 0.0604 0.0449 0.0597 0.0355 0.0531 0.0343 0.1052 0.2120
## 7  0.0126 0.0149 0.0641 0.1732 0.2565 0.2559 0.2947 0.4110 0.4983 0.5920
## 8  0.0473 0.0509 0.0819 0.1252 0.1783 0.3070 0.3008 0.2362 0.3830 0.3759
## 9  0.0099 0.0484 0.0299 0.0297 0.0652 0.1077 0.2363 0.2385 0.0075 0.1882
## 10 0.0151 0.0320 0.0599 0.1050 0.1163 0.1734 0.1679 0.1119 0.0889 0.1205
## # ... with 50 more rows, and 51 more variables: V11 &lt;dbl&gt;, V12 &lt;dbl&gt;,
## #   V13 &lt;dbl&gt;, V14 &lt;dbl&gt;, V15 &lt;dbl&gt;, V16 &lt;dbl&gt;, V17 &lt;dbl&gt;, V18 &lt;dbl&gt;,
## #   V19 &lt;dbl&gt;, V20 &lt;dbl&gt;, V21 &lt;dbl&gt;, V22 &lt;dbl&gt;, V23 &lt;dbl&gt;, V24 &lt;dbl&gt;,
## #   V25 &lt;dbl&gt;, V26 &lt;dbl&gt;, V27 &lt;dbl&gt;, V28 &lt;dbl&gt;, V29 &lt;dbl&gt;, V30 &lt;dbl&gt;,
## #   V31 &lt;dbl&gt;, V32 &lt;dbl&gt;, V33 &lt;dbl&gt;, V34 &lt;dbl&gt;, V35 &lt;dbl&gt;, V36 &lt;dbl&gt;,
## #   V37 &lt;dbl&gt;, V38 &lt;dbl&gt;, V39 &lt;dbl&gt;, V40 &lt;dbl&gt;, V41 &lt;dbl&gt;, V42 &lt;dbl&gt;,
## #   V43 &lt;dbl&gt;, V44 &lt;dbl&gt;, V45 &lt;dbl&gt;, V46 &lt;dbl&gt;, V47 &lt;dbl&gt;, V48 &lt;dbl&gt;,
## #   V49 &lt;dbl&gt;, V50 &lt;dbl&gt;, V51 &lt;dbl&gt;, V52 &lt;dbl&gt;, V53 &lt;dbl&gt;, V54 &lt;dbl&gt;,
## #   V55 &lt;dbl&gt;, V56 &lt;dbl&gt;, V57 &lt;dbl&gt;, V58 &lt;dbl&gt;, V59 &lt;dbl&gt;, V60 &lt;dbl&gt;,
## #   Class &lt;fctr&gt;</code></pre>
<p>훈련데이터셋이 148개, 테스트데이터셋이 60개로 잘 나누어진 것을 볼 수 있다.</p>
<p><br><br></p>
<h2 id="머신러닝-알고리즘별-최적의-모수를-찾기-위한-학습방법-사전-설정">머신러닝 알고리즘별 최적의 모수를 찾기 위한 학습방법 사전 설정</h2>
<p>K 최근접 이웃모델 즉 KNN(K-Neareast Neighbors) 을 통해 명목변수를 예측하려 한다면<br />
그 이전에 선행되어야 할 것이 &quot;K&quot; 를 몇개로 설정할 것이냐이다.<br />
랜덤포레스트(RandomForest) 를 이용하려 한다면 노드를 나눌 기준으로 고려할 변수의 개수인 &quot;mtry&quot; 를 얼마로 정해야 할지도 마찬가지이다.<br />
위의 예시에서 &quot;K&quot;, &quot;mtry&quot; 와 같은 모수는 예비조사를 통해 사람이 정하거나, 데이터에 근거해 최적의 군집개수를 정하는 과정을 통해 (방법이 어떻게 되었든) 정해져야 모델링을 할 수 있다. (단 비모수적 모델링이라면 제외되는 이야기이겠다)<br />
이처럼 알고리즘 별로 반드시 정해져야 모델링을 실시 할 수 있는 모수들을 caret package 에선 &quot;Tuning parameters&quot; 로 설명하고 있고, LOOCV, K-fold cross validation 등과 같은 방법을 통해서 데이터에 근거한 최적의 parameter 를 찾는 과정을 거친다.</p>
<p>알고리즘별로 튜닝 파라미터 개수는 달라지는데 p개의 파라미터일 경우 <span class="math inline">3<sup><em>P</em></sup></span> 의 그리드를 탐색하여 후보모델들을 테스트하게 된다.</p>
<p>예를 들면 이렇다.<br />
KNN(K-Neareast Neighbors) 는 K 하나인 단모수이므로 <span class="math inline">3<sup>1</sup> = 3</span> 인 3가지 K 값들을 후보로 두고 모델을 비교하게 된다.<br />
RRLDA(Robust Regularized Linear Discriminant Analysis) 의 경우 모수의 개수가 lambda, hp, penalty 총 3개인데 <span class="math inline">3<sup>3</sup> = 27</span> 인 27가지 후보를 비교하게 될 것이다.</p>
<p>3개이던 27개 이던 다수의 후보에 대해서 비교하는 방식 또한 고려대상이다.<br />
후보의 비교방법을 K-fold cross validation 으로 한다고 할 경우 몇번을 접어 cross validation 을 할 것이냐 란 질문의 K 를 정해야 한다.<br />
caret 패키지에선 <code>trainControl()</code> 함수를 통해 일관된 비교방법을 각 후보에게 통일되게 적용하여 평가할 수 있게 도와준다.</p>
<p>아래 코드는 10-fold cross validation 을 5번 반복하여 가장 좋은 후보의 파라미터 그리드를 찾게 해주는 일종의 장치를 만드는 코드이다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fitControl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">number =</span> <span class="dv">10</span>, <span class="dt">repeats =</span> <span class="dv">5</span>)</code></pre></div>
<p>이렇게 만들어진 비교방법에 대한 정보가 담겨있는 <code>fitControl</code> 객체는 추후에 학습 과정에서 사용하게 될 것이다.</p>
<p><br><br></p>
<h2 id="randomforest-로-학습시켜보기">RandomForest 로 학습시켜보기</h2>
<p>본격적으로 훈련데이터셋을 이용해 학습을 시켜보겠다.<br />
학습을 위한 표준화된 인터페이스는 바로 <code>train()</code> 함수이다.<br />
이함수에서 <code>method</code> 인자만 바꿔주면 원하는 학습모델 알고리즘을 구현할 수 있게 된다.</p>
<p>아래 코드는 랜덤포레스트를 통해 훈련데이터셋을 학습하는 코드다.<br />
랜덤포레스트 알고리즘을 통해 학습할 것을 <code>method = &quot;rf&quot;</code> 를 통해 선언한다.<br />
랜덤포레스트에서 Tuning parameter 에 해당되는 &quot;mtry&quot; 는 10-fold cross validation 을 5번 반복하여 가장 좋게 평가된 것을 선택하는 후보채택방법인 <code>fitControl</code> 객체를 <code>trControl</code> 인자에 입력한다.<br />
<code>verbose</code> 인자는 기본적으로 <code>TRUE</code> 로 설정되어 있는데 &quot;mtry&quot; 선정과정이 적나라하게 모두 출력된다.<br />
이 출력을 막고싶었기 때문에 <code>FALSE</code> 로 해제하였다.</p>
<p>더해서 랜덤포레스트를 알고리즘을 이용하기 위한 원 소스인 randomForest 패키지 여부를 먼저 확인하는 과정이 있으므로<br />
만약 randomForest 패키지가 없다면 설치를 시도할 것인지를 물어볼 것이다. 이럴땐 패키지를 설치하겠다는 의미인 &quot;1&quot;을 입력하면 설치 이후 학습을 연이어 진행한다.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rf_fit &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> training, <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="dt">trControl =</span> fitControl, <span class="dt">verbose =</span> F)
rf_fit</code></pre></div>
<pre><code>## Random Forest 
## 
## 148 samples
##  60 predictor
##   2 classes: &#39;M&#39;, &#39;R&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## Summary of sample sizes: 133, 133, 133, 133, 133, 133, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##    2    0.8401905  0.6762815
##   31    0.7969524  0.5898194
##   60    0.7793333  0.5547874
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 2.</code></pre>
<p>mtry 후보는 2, 31, 60 개로 자동설정된 것을 볼 수 있고, 이 중 Kappa 통계량과 정확도에 의해서 mtry = 2 가 최종적으로 선정된 것을 볼 수 있다.<br />
선정과정을 자세하게 보고 싶을 경우엔 <code>verbose = F</code> 를 삭제하고 실행해 보면 좋을 수도 있겠다.</p>
<p><br><br></p>
<h2 id="테스트셋에-적용하여-정확도-확인">테스트셋에 적용하여 정확도 확인</h2>
<p>보통 훈련데이터셋을 이용해 모델 학습하면<br />
바로 해보고 싶은 것이 Test dataset 에 적용시켜 영리한 모델인지를 확인해 보는 것이다.</p>
<p>제너릭 함수인 <code>predict()</code> 를 이용해 볼 수 도 있겠지만</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(rf_fit, <span class="dt">newdata =</span> testing)</code></pre></div>
<pre><code>##  [1] M M R M R R M M R M R R R R M R R R R R R R R M M R R M M R M M M M M
## [36] M M M M M M M M M M M R M M R M M M M M M M M M M
## Levels: M R</code></pre>
<p>caret package 의 <code>confusionMatrix()</code> 를 곁들이면 <a href="https://en.wikipedia.org/wiki/Confusion_matrix">혼돈메트릭스(Confusion Matrix)</a> 및 정확도외 다양한 통계량까지 출력된다.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(rf_fit, <span class="dt">newdata =</span> testing) %&gt;%<span class="st"> </span><span class="kw">confusionMatrix</span>(testing$Class)</code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  M  R
##          M 30  9
##          R  3 18
##                                           
##                Accuracy : 0.8             
##                  95% CI : (0.6767, 0.8922)
##     No Information Rate : 0.55            
##     P-Value [Acc &gt; NIR] : 4.67e-05        
##                                           
##                   Kappa : 0.5876          
##  Mcnemar&#39;s Test P-Value : 0.1489          
##                                           
##             Sensitivity : 0.9091          
##             Specificity : 0.6667          
##          Pos Pred Value : 0.7692          
##          Neg Pred Value : 0.8571          
##              Prevalence : 0.5500          
##          Detection Rate : 0.5000          
##    Detection Prevalence : 0.6500          
##       Balanced Accuracy : 0.7879          
##                                           
##        &#39;Positive&#39; Class : M               
## </code></pre>
<p>60개의 테스트 데이터셋 중 12개가 오분류 되어 약 80% 의 정확도를 가진 것으로 볼 수 있다.</p>
<p><br><br></p>
<h2 id="tuning-parameters-의-그리드-조정하기">Tuning parameters 의 그리드 조정하기</h2>
<h3 id="사용자-검색-그리드custom-search-grid">사용자 검색 그리드(custom search grid)</h3>
<p>최적 파라미터 선정 시 탐색범위와 그리드를 수동으로 조절할 수 있다.<br />
자동으로 <span class="math inline">3<sup><em>P</em></sup></span> 공식에 의해 정해진 mtry 의 후보는 2, 31, 60 로 3개가 되었다.<br />
만약 더 많은 후보와 상대평가하고 싶을 경우 후보를 사용자가 직접 설정할 수 있다는 것이다.</p>
<p>아래 코드는 mtry 의 후보를 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 로 바꾸어 설정하고 이 중에서 채택해 보는 코드이다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">customGrid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">mtry =</span> <span class="dv">1</span>:<span class="dv">10</span>)
rf_fit2 &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> training, <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="dt">trControl =</span> fitControl, <span class="dt">tuneGrid =</span> customGrid, <span class="dt">verbose =</span> F)

rf_fit2</code></pre></div>
<pre><code>## Random Forest 
## 
## 148 samples
##  60 predictor
##   2 classes: &#39;M&#39;, &#39;R&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## Summary of sample sizes: 133, 133, 134, 133, 133, 133, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##    1    0.8283810  0.6509334
##    2    0.8449524  0.6849450
##    3    0.8352381  0.6654026
##    4    0.8366667  0.6687853
##    5    0.8390476  0.6740847
##    6    0.8349524  0.6651819
##    7    0.8245714  0.6441155
##    8    0.8406667  0.6766160
##    9    0.8322857  0.6603633
##   10    0.8284762  0.6522812
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 2.</code></pre>
<p>후보를 사용자 검색에 의해 늘려보아도 이전과 같이 mtry = 2 가 최적의 파라미터로 선정되는 것을 볼 수 있다.</p>
<h3 id="랜덤-검색-그리드random-selection-of-tuning-parameter-combinations">랜덤 검색 그리드(<a href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf">random selection of tuning parameter combinations</a>)</h3>
<p>튜닝 파라미터의 개수가 많으면 많아질수록 탐색그리드의 개수는 지수적으로 증가하게 되고 동일한 간격의 그리드 구성으로 인해 탐색과정이 비효율적이 될 수 있다.<br />
지금까지 튜닝 파라미터가 한개인 랜덤포레스트를 예시로 했는데 이번에는 튜닝 파라미터가 2개인 RDA(Regularized Discriminant Analysis) 를 통해 훈련을 해보겠다.<br />
<code>method = &quot;rda&quot;</code> 를 통해 알고리즘을 RDA 로 선언할 수 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rda_fit &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> training, <span class="dt">method =</span> <span class="st">&quot;rda&quot;</span>, <span class="dt">trControl =</span> fitControl, <span class="dt">verbose =</span> F)

rda_fit</code></pre></div>
<pre><code>## Regularized Discriminant Analysis 
## 
## 148 samples
##  60 predictor
##   2 classes: &#39;M&#39;, &#39;R&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## Summary of sample sizes: 133, 133, 133, 133, 134, 133, ... 
## Resampling results across tuning parameters:
## 
##   gamma  lambda  Accuracy   Kappa    
##   0.0    0.0     0.5687619  0.1108443
##   0.0    0.5     0.7151429  0.4264147
##   0.0    1.0     0.7499048  0.4979435
##   0.5    0.0     0.8162857  0.6298722
##   0.5    0.5     0.8340000  0.6646203
##   0.5    1.0     0.7962857  0.5907191
##   1.0    0.0     0.6405714  0.2773524
##   1.0    0.5     0.6392381  0.2748428
##   1.0    1.0     0.6406667  0.2776946
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final values used for the model were gamma = 0.5 and lambda = 0.5.</code></pre>
<p>총 9개의 파라미터 조합을 비교하는 것을 볼 수 있다.<br />
바로 위에 소개한 사용자 검색 그리드 역시 <code>expand.grid()</code> 함수를 이용하여 동일간격 그리드를 검색하게 될 것이다. 이와는 다르게 랜덤 검색 그리드를 이용하면 동일간격 조건을 파괴시켜 파라미터 조합을 구성할 수 도 있다.<br />
<code>trainControl()</code> 함수의 <code>search = &quot;random&quot;</code> 을 통해 검색 타입을 랜덤으로 바꾼다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fitControl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">number =</span> <span class="dv">10</span>, <span class="dt">repeats =</span> <span class="dv">5</span>, <span class="dt">search =</span> <span class="st">&quot;random&quot;</span>)</code></pre></div>
<p>이후 <code>rda_fit2</code> 라는 객체이름으로 학습을 다시 시도하고 저장해 본다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rda_fit2 &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> training, <span class="dt">method =</span> <span class="st">&quot;rda&quot;</span>, <span class="dt">trControl =</span> fitControl, <span class="dt">verbose =</span> F)
rda_fit2</code></pre></div>
<pre><code>## Regularized Discriminant Analysis 
## 
## 148 samples
##  60 predictor
##   2 classes: &#39;M&#39;, &#39;R&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## Summary of sample sizes: 134, 133, 134, 133, 133, 133, ... 
## Resampling results across tuning parameters:
## 
##   gamma      lambda      Accuracy   Kappa    
##   0.1905631  0.09127881  0.8182857  0.6359082
##   0.4408472  0.90947514  0.8528571  0.7038502
##   0.5510134  0.81992551  0.8500952  0.6971829
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final values used for the model were gamma = 0.4408472 and lambda
##  = 0.9094751.</code></pre>
<p>튜닝파라미터가 gamma, lambda 2개인데 검색타입을 랜덤으로 바꾸는 순간 <span class="math inline">3<sup><em>P</em></sup></span> 공식으로 후보군을 설정하지 않는 것을 확인할 수 있다.<br />
수동으로 튜닝파라미터 조합개수를 늘려볼 필요가 있다. 이땐 <code>train()</code> 함수의 <code>tuneLength</code> 인자를 이용하면 된다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rda_fit2 &lt;-<span class="st"> </span><span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> training, <span class="dt">method =</span> <span class="st">&quot;rda&quot;</span>, <span class="dt">trControl =</span> fitControl, <span class="dt">tuneLength =</span> <span class="dv">50</span>, <span class="dt">verbose =</span> F)
rda_fit2</code></pre></div>
<pre><code>## Regularized Discriminant Analysis 
## 
## 148 samples
##  60 predictor
##   2 classes: &#39;M&#39;, &#39;R&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## Summary of sample sizes: 133, 133, 133, 133, 134, 133, ... 
## Resampling results across tuning parameters:
## 
##   gamma       lambda       Accuracy   Kappa    
##   0.02467175  0.046240696  0.7835238  0.5655217
##   0.04621138  0.002756874  0.7919048  0.5824003
##   0.07368577  0.095874564  0.8066667  0.6118768
##   0.07701965  0.222859888  0.8202857  0.6398213
##   0.08188038  0.929917497  0.8123810  0.6225995
##   0.08238852  0.477012957  0.8337143  0.6662831
##   0.08304677  0.278592744  0.8242857  0.6477351
##   0.13057207  0.394850662  0.8407619  0.6801815
##   0.16005396  0.740609627  0.8583810  0.7147504
##   0.16216482  0.825921020  0.8475238  0.6931098
##   0.17577373  0.014122051  0.8121905  0.6232475
##   0.18138144  0.343863922  0.8367619  0.6723626
##   0.19299614  0.250964919  0.8272381  0.6530806
##   0.21154934  0.924441815  0.8380952  0.6743253
##   0.29112614  0.062553048  0.8165714  0.6318989
##   0.32592688  0.815187029  0.8491429  0.6957937
##   0.33401985  0.355391729  0.8343810  0.6667045
##   0.33579572  0.585321935  0.8450476  0.6877346
##   0.38974907  0.595071037  0.8462857  0.6901836
##   0.43134665  0.053143749  0.8057143  0.6091455
##   0.46238233  0.225248311  0.8180952  0.6334203
##   0.48010298  0.220008595  0.8167619  0.6308603
##   0.52875129  0.900502936  0.8369524  0.6717790
##   0.59418161  0.835826412  0.8410476  0.6796135
##   0.64002373  0.715450695  0.8450476  0.6871024
##   0.66951286  0.080254850  0.8084762  0.6133645
##   0.66992710  0.557613578  0.8411429  0.6791014
##   0.68394252  0.120018550  0.8085714  0.6136620
##   0.70021389  0.623248231  0.8423810  0.6819366
##   0.70083494  0.075418255  0.8072381  0.6108154
##   0.71019128  0.776717800  0.8287619  0.6548209
##   0.72006479  0.588846389  0.8301905  0.6573055
##   0.73698825  0.234913379  0.8139048  0.6242272
##   0.74356291  0.148414826  0.8139048  0.6242293
##   0.75140091  0.109355597  0.8112381  0.6189670
##   0.75224234  0.263593657  0.8179048  0.6324297
##   0.76679423  0.973216361  0.7871429  0.5722820
##   0.79372463  0.790550417  0.8045714  0.6062931
##   0.82214953  0.130020319  0.8098095  0.6156629
##   0.82467612  0.550611505  0.8059048  0.6081189
##   0.82612455  0.693889297  0.7966667  0.5900626
##   0.84879017  0.495823009  0.7993333  0.5949617
##   0.85219803  0.931135875  0.7571429  0.5118228
##   0.86055616  0.314226715  0.8045714  0.6050836
##   0.86385220  0.089582003  0.7966667  0.5883829
##   0.87890898  0.058559475  0.7939048  0.5827761
##   0.89994468  0.677635454  0.7641905  0.5254671
##   0.93039376  0.101246271  0.7522857  0.5002045
##   0.93660375  0.971543712  0.7182857  0.4340252
##   0.95149425  0.689020876  0.7141905  0.4257570
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final values used for the model were gamma = 0.160054 and lambda
##  = 0.7406096.</code></pre>
<p><code>tuneLength = 50</code> 로 설정해본 결과이다.<br />
기본 그리드 검색방법에 비교해 보면 채택된 파라미터의 값이 소수점이 더 많아져 자연스럽게 정밀해 진 것을 확인할 수 있다.<br />
이처럼 튜닝파라미터를 랜덤하게 50개로 설정하여 조금 더 융통성 있는 최적의 파라미터 튜닝 방법을 고려해 볼 수도 있겠다.</p>
<p><br><br></p>
<h2 id="병렬처리parallel-processing">병렬처리(Parallel Processing)</h2>
<p>병렬처리를 통해 빠른 탐색 전략을 취할 수 있다.<br />
doMC 패키지와의 연계를 지원하는 caret 패키지는 학습 시 생기는 많은 연산을 병렬처리를 통해 시간 비용을 절감시킬 수 있다. (단 doMC package 는 Unix 계열 머신에서 사용이 가능하다) 특히 튜닝파라미터의 조합 수가 많으면 많을수록 병렬처리는 많은 효용이 있을 것이다.</p>
<p>필요에 따라 doMC 패키지를 설치하고 로드한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;doMC&quot;)</span>
<span class="kw">library</span>(<span class="st">&quot;doMC&quot;</span>)</code></pre></div>
<p>doMC 패키지를 로드하면 <code>getDoParWorkers()</code> 를 통해 현재 활성화된 코어수를 확인할 수 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">getDoParWorkers</span>() <span class="co"># default cores count</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>기본적으론 세팅 이전엔 1코어임을 확인할 수 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">time &lt;-<span class="st"> </span><span class="kw">system.time</span>({
  <span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> training, <span class="dt">method =</span> <span class="st">&quot;gbm&quot;</span>, <span class="dt">trControl =</span> fitControl, <span class="dt">verbose =</span> F)
})
time</code></pre></div>
<pre><code>##    user  system elapsed 
## 218.508   1.495 221.734</code></pre>
<p>이때 GBM(Stochastic Gradient Boosting Model)알고리즘으로 학습에 소요되는 시간은 222 초 내외이다.</p>
<p>이번에는 <code>registerDoMC()</code> 함수를 이용해 코어수를 2개로 늘린 후 학습에 소요되는 시간을 비교해보자.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">registerDoMC</span>(<span class="dt">cores =</span> <span class="dv">2</span>)
<span class="kw">getDoParWorkers</span>()</code></pre></div>
<pre><code>## [1] 2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">time &lt;-<span class="st"> </span><span class="kw">system.time</span>({
  <span class="kw">train</span>(Class ~<span class="st"> </span>., <span class="dt">data =</span> training, <span class="dt">method =</span> <span class="st">&quot;gbm&quot;</span>, <span class="dt">trControl =</span> fitControl, <span class="dt">verbose =</span> F)
})
time</code></pre></div>
<pre><code>##    user  system elapsed 
##   0.595   0.067  44.684</code></pre>
<p>이때 학습에 소요되는 시간은 45 초 내외이다.<br />
확실히 소요시간이 줄어든 것을 볼 수 있다.</p>
<p><br><br></p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://topepo.github.io/caret" class="uri">https://topepo.github.io/caret</a></li>
</ul>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>2017-04-23 기준으로 글이 작성 및 수정 되었다<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>1: yes, 2: no<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>예제가 Classification 일때 이므로 Regression 일때는 논외다<a href="#fnref3">↩</a></p></li>
</ol>
</section>
</div>
    <div class="share-page">
    <span style="float: left;">Share this on &rarr;&nbsp;&nbsp;</span>
    
    <!-- Twitter -->
     <a href="https://twitter.com/share" class="twitter-share-button" data-via="">Tweet</a>
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

    <!-- Google + -->
    <div class="g-plus" data-action="share" data-annotation="bubble"></div>
    <script src="https://apis.google.com/js/platform.js" async defer></script>

    <!-- Facebook -->
    <div class="fb-share-button" data-href="https://lovetoken.github.io/r/2017/04/23/caret_package.html" data-layout="button_count" style="position: relative; top: -8px; left: 3px;"></div>
</div>
<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.6&appId=";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
</div>



    
    
        
            
                
                <div class="panel-body">
                <h4>Related Posts</h4>
                <ul>
                
                <li class="relatedPost">
                    <a href="https://lovetoken.github.io/r/2018/01/14/CV.html">변동계수의 개념과 R에서의 실습</a>
                    
                        (Categories: <a href="/category/R">R</a>)
                    
                </li>
                
                
            
        
    

    
    
        
            
        
    

    
    
        
            
                
                <li class="relatedPost">
                    <a href="https://lovetoken.github.io/r/2018/01/02/allequal.html">R에서 all.equal() 함수를 이용한 객체의 동일성 확인하기</a>
                    
                        (Categories: <a href="/category/R">R</a>)
                    
                </li>
                
                
            
        
    

    
    
        
            
        
    

    
    
        
            
                
                <li class="relatedPost">
                    <a href="https://lovetoken.github.io/r/2017/10/07/guessEncoding.html">R에서 readr package 의 guess_encoding() 함수를 이용한 Text 파일의 인코딩 타입 추론</a>
                    
                        (Categories: <a href="/category/R">R</a>)
                    
                </li>
                
                
            
        
    

    
    
        
            
                
                <li class="relatedPost">
                    <a href="https://lovetoken.github.io/r/data_visualization/2017/06/16/plotFunction.html">R에서 기본 내장 graphics package를 이용한 데이터 시각화</a>
                    
                        (Categories: <a href="/category/R">R</a>, <a href="/category/Data_Visualization">Data_Visualization</a>)
                    
                </li>
                
                
            
        
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
                
                <li class="relatedPost">
                    <a href="https://lovetoken.github.io/r/2017/05/30/MatrixProduct.html">R에서 행렬 간 이루어지는 다양한 곱셈에 대해 알아보기 (행렬의 곱셈, 하다마드 곱셈, 크로네커 곱셈)</a>
                    
                        (Categories: <a href="/category/R">R</a>)
                    
                </li>
                
                
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
                
                <li class="relatedPost">
                    <a href="https://lovetoken.github.io/r/2017/04/16/vif.html">R에서 car::vif() 함수를 이용한 분산팽창요인(Variance Inflation Factor) 구하기</a>
                    
                        (Categories: <a href="/category/R">R</a>)
                    
                </li>
                
                
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    
        
            
        
    

    
    
        
            
        
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
        
    


    </ul>
    </div>


<div class="PageNavigation">
  
    <a class="prev" href="/r/2017/04/16/vif.html">&laquo; R에서 car::vif() 함수를 이용한 분산팽창요인(Variance Inflation Factor) 구하기</a>
  
  
    <a class="next" href="/etc/2017/05/04/Typeform.html">온라인 설문지 서비스 Typeform 소개, 설문조사 방법에 대한 설문조사 &raquo;</a>
  
</div>


<div class="disqus-comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* <![CDATA[ */

        var disqus_shortname = "lovetoken";
        var disqus_identifier = "https://lovetoken.github.io_R에서 caret package 를 이용한 데이터 학습 간편화 전략";
        var disqus_title = "R에서 caret package 를 이용한 데이터 학습 간편화 전략";

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    /* ]]> */
    </script>
</div>

                <footer>
                    Copyleft by Lovetoken
                     
                    - <a href="https://github.com/lovetoken">https://github.com/lovetoken</a> - Powered by Jekyll.
                    

                    <div class="btn-github" style="float:right;">
                        <iframe src="https://ghbtns.com/github-btn.html?user=agusmakmun&repo=agusmakmun.github.io&type=star&count=true" frameborder="0" scrolling="0" width="85" height="20px"></iframe>                    
                        <iframe src="https://ghbtns.com/github-btn.html?user=agusmakmun&repo=agusmakmun.github.io&type=fork&count=true" frameborder="0" scrolling="0" width="85" height="20px"></iframe>
                    </div>
                </footer>
            </div><!-- end /.col-sm-8 -->
        </div><!-- end /.container -->

        <!-- Bootstrap core JavaScript
        ================================================== -->
        <!-- Placed at the end of the document so the pages load faster -->
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
        <script src="//code.jquery.com/jquery-migrate-1.2.1.min.js"></script>
        <script src="/static/js/bootstrap.min.js"></script>
        <script src="/static/js/super-search.js"></script>
        <script src="/static/js/thickbox-compressed.js"></script>
        <script src="/static/js/projects.js"></script>
    </body>
</html>
